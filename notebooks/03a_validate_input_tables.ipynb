{
 "cells": [
  {
   "cell_type": "raw",
   "id": "be545097",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\\setcounter{secnumdepth}{0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84edd88",
   "metadata": {},
   "source": [
    "# 03a - Validation and Descriptive Summary of the Analysis Dataset\n",
    "\n",
    "## 0. Overview\n",
    "\n",
    "This notebook loads and validates the component tables that together form the admission-level analysis dataset used in downstream descriptive and outcome analyses.\n",
    "\n",
    "Specifically, it inspects:\n",
    "- A non-ICU adult hospital admission cohort table defined at the hospital admission (HADM) level\n",
    "- A corresponding early RAAS inhibitor exposure table, also defined at the HADM level and constructed upstream using a fixed early-in-admission exposure window\n",
    "\n",
    "The primary objective of this notebook is to verify structural integrity and internal consistency prior to analysis. Validation checks include confirmation of a one-to-one correspondence between rows and hospital admissions, alignment of exposure indicators with admission-level identifiers, logical consistency among exposure variables, and the absence of unexpected missingness in key fields.\n",
    "\n",
    "No tables are created or modified in this notebook; all data are read-only and assumed to have been materialized upstream in BigQuery. The validated tables serve as stable inputs for subsequent baseline characterization and outcome modeling notebooks.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In observational clinical analyses, careful validation of analytic inputs is essential before performing descriptive summaries or outcome modeling. Errors such as duplicate admissions, unintended row expansion during joins, inconsistent exposure definitions, or silent missingness can introduce bias or invalidate downstream results.\n",
    "\n",
    "This notebook focuses on validating the admission-level component tables used to define the analytic population and early RAAS inhibitor exposure in a non-ICU cohort derived from the MIMIC-IV database. The cohort table captures demographic, administrative, and hospitalization characteristics at the level of individual hospital admissions, while the exposure table encodes early use of angiotensin-converting enzyme inhibitors and angiotensin receptor blockers based on pre-specified, time-restricted definitions applied upstream.\n",
    "\n",
    "By systematically inspecting row counts, key identifiers, data types, and logical relationships among exposure indicators, this notebook establishes confidence that the analytic inputs preserve the intended admission-level structure and are suitable for downstream descriptive and outcome analyses.\n",
    "\n",
    "## 2. Data Sources\n",
    "\n",
    "- **MIMIC-IV v3.1** (BigQuery public dataset)\n",
    "- Project: `mimic-iv-portfolio`\n",
    "\n",
    "**Source Tables:**\n",
    "  - `nonicu_raas.nonicu_admissions`<br>\n",
    "    (created in [02_exposure.ipynb](02_exposure.ipynb) using [02_exclude_icu_admissions.sql](../sql/02_exclude_icu_admissions.sql))\n",
    "    \n",
    "  - `nonicu_raas.exposure_raas_early`<br>\n",
    "    (created in [02_exposure.ipynb](02_exposure.ipynb) using [03_define_exposure_raas_early.sql](../sql/03_define_exposure_raas_early.sql))\n",
    "\n",
    "These intermediate tables were generated using SQL-based preprocessing pipelines in BigQuery to ensure reproducibility and a clear separation between data extraction, variable construction, and downstream analysis.\n",
    "\n",
    "## 3. Cohort Definition\n",
    "\n",
    "The analytic cohort consists of adult, non-ICU hospital admissions derived from the MIMIC-IV database, with inclusion and exclusion criteria applied upstream using SQL-based data extraction procedures.\n",
    "\n",
    "Specifically, hospital admissions with any recorded ICU stay were excluded by linking admissions to the MIMIC-IV ICU module and removing all admissions with at least one ICU encounter. As a result, the cohort represents adult non-ICU hospital admissions defined at the hospital admission (HADM) level.\n",
    "\n",
    "In this notebook, the cohort is represented by a pre-materialized BigQuery table containing one row per hospital admission, uniquely identified by `subject_id` and `hadm_id`. The table is loaded in read-only mode for inspection and validation only; no cohort construction or modification is performed here.\n",
    "\n",
    "## 4. Exposure Definition\n",
    "\n",
    "Exposure information was merged into the analytic cohort at the hospital admission level using a left join on `hadm_id` (and `subject_id` as a secondary identifier). Admissions without recorded early RAAS inhibitor exposure were retained and explicitly coded as unexposed, rather than treated as missing.\n",
    "\n",
    "Exposure status is encoded as admission-level binary indicators for early ACE inhibitor use, early ARB use, combined exposure to both drug classes, and a composite indicator reflecting exposure to either class. These variables were constructed upstream using time-restricted prescription records and are loaded here without modification.\n",
    "\n",
    "In this notebook, exposure variables are evaluated solely for row alignment, logical consistency (e.g., agreement between component and composite indicators), and completeness, without redefining exposure criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94b978",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## 5. Data Preparation and Sanity Checks\n",
    "### 5.1 Dataset Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8b99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: mimic-iv-portfolio | ADC default: mimic-iv-portfolio\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.auth import default\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Define project ID, dataset, and table references\n",
    "PROJECT_ID = \"mimic-iv-portfolio\"\n",
    "DATASET = \"nonicu_raas\"\n",
    "\n",
    "TABLE_NONICU = f\"{PROJECT_ID}.{DATASET}.nonicu_admissions\"   # Created in 02_exclude_icu_admissions.sql\n",
    "TABLE_EXPO = f\"{PROJECT_ID}.{DATASET}.exposure_raas_early\"   # Created in 03_define_exposure_raas_early.sql\n",
    "\n",
    "# 2. Get ADC credentials\n",
    "\n",
    "creds, adc_project = default()\n",
    "client = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
    "\n",
    "print(\"Connected to:\", PROJECT_ID, \"| ADC default:\", adc_project)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43273120",
   "metadata": {},
   "source": [
    "### 5.2 Dataset Overview and Descriptive Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1597e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for read-only SELECT queries â†’ DataFrame\n",
    "def query_to_df(query) :\n",
    "    \"\"\"\n",
    "    Run a SELECT query in BigQuery and return a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    job = client.query(query)\n",
    "    return job.to_dataframe(create_bqstorage_client=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ffb61",
   "metadata": {},
   "source": [
    "### 5.3 Loading Intermediate BigQuery Tables into pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c38df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_nonicu = f\"SELECT * FROM {TABLE_NONICU}\"\n",
    "q_expo = f\"SELECT * FROM {TABLE_EXPO}\"\n",
    "\n",
    "df_nonicu = query_to_df(q_nonicu)\n",
    "df_expo = query_to_df(q_expo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d974200",
   "metadata": {},
   "source": [
    "### 5.4 Schema and Data Type Inspection of the Non-ICU Admissions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 460786 entries, 0 to 460785\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   subject_id            460786 non-null  Int64         \n",
      " 1   hadm_id               460786 non-null  Int64         \n",
      " 2   admittime             460786 non-null  datetime64[us]\n",
      " 3   dischtime             460786 non-null  datetime64[us]\n",
      " 4   deathtime             2324 non-null    datetime64[us]\n",
      " 5   hospital_expire_flag  460786 non-null  Int64         \n",
      " 6   admission_type        460786 non-null  object        \n",
      " 7   admission_location    460785 non-null  object        \n",
      " 8   discharge_location    311810 non-null  object        \n",
      " 9   insurance             452862 non-null  object        \n",
      " 10  language              460377 non-null  object        \n",
      " 11  marital_status        454118 non-null  object        \n",
      " 12  race                  460786 non-null  object        \n",
      " 13  gender                460786 non-null  object        \n",
      " 14  age                   460786 non-null  Int64         \n",
      " 15  anchor_age            460786 non-null  Int64         \n",
      " 16  anchor_year           460786 non-null  Int64         \n",
      " 17  anchor_year_group     460786 non-null  object        \n",
      " 18  hosp_los              460786 non-null  float64       \n",
      " 19  race_group            460786 non-null  object        \n",
      "dtypes: Int64(6), datetime64[us](3), float64(1), object(10)\n",
      "memory usage: 72.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_nonicu.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4739bea",
   "metadata": {},
   "source": [
    "### 5.5 Schema and Data Type Inspection of the Early RAAS Exposure Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f1118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 460786 entries, 0 to 460785\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count   Dtype\n",
      "---  ------           --------------   -----\n",
      " 0   subject_id       460786 non-null  Int64\n",
      " 1   hadm_id          460786 non-null  Int64\n",
      " 2   acei_early       460786 non-null  Int64\n",
      " 3   arb_early        460786 non-null  Int64\n",
      " 4   raas_both_early  460786 non-null  Int64\n",
      " 5   raas_any_early   460786 non-null  Int64\n",
      "dtypes: Int64(6)\n",
      "memory usage: 23.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_expo.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
